{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyP7zu73M1UuwYKQJzyh4g6S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["In this project, we train a fully connect mlp and a CNN model based on CIFAR10 dataset, then compare their performance.\n"],"metadata":{"id":"yYDOpqpwkjBU"}},{"cell_type":"code","source":["import torch\n","import torch.nn as n\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, random_split\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.datasets import CIFAR10\n","from IPython.display import Image"],"metadata":{"id":"zzl-sl1IY6bX"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v_WqUcPTYxT3"},"outputs":[],"source":["# Set up a transform to convert the images to tensor\n","transform = transforms.Compose([transforms.ToTensor()])\n","\n","# Load the CIFAR-10 training dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","num_train = len(trainset)\n","num_val = int(0.1 * num_train)\n","num_train -= num_val\n","\n","train_dataset, val_dataset = random_split(trainset, [num_train, num_val])\n","\n","# Load the CIFAR-10 test dataset\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","\n","# Function to show an image\n","def imshow(img):\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.axis('off')  # turn off axis\n","\n","# Display five random images along with their corresponding labels\n","fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n","for i in range(5):\n","    idx = random.randint(0, len(trainset)-1)\n","    image, label = trainset[idx]\n","    axs[i].imshow(np.transpose(image.numpy(), (1, 2, 0)))\n","    axs[i].set_title(classes[label])\n","    axs[i].axis('off')\n","\n","plt.show()\n","\n","# Create a bar plot to visualize the distribution of classes in the CIFAR-10 dataset\n","class_counts = {classname: 0 for classname in classes}\n","for _, label in trainset:\n","    class_counts[classes[label]] += 1\n","\n","# Plotting the bar chart\n","plt.figure(figsize=(10, 6))\n","plt.bar(class_counts.keys(), class_counts.values())\n","plt.xlabel('Classes')\n","plt.ylabel('Number of Images')\n","plt.title('Distribution of Classes in CIFAR-10 Dataset')\n","plt.show()"],"metadata":{"id":"AvdH3kjNZAX5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Mean and standard deviation values for standardization\n","mean = [0.4914, 0.4822, 0.4465]\n","std = [0.2023, 0.1994, 0.2010]\n","# Define the transform including the normalization step\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","# Load the CIFAR-10 training dataset\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","\n","num_train = len(trainset)\n","num_val = int(0.1 * num_train)\n","num_train -= num_val\n","\n","train_dataset, val_dataset = random_split(trainset, [num_train, num_val])\n","\n","# Load the CIFAR-10 test dataset\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"AxEFHjzUZCQF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","# Set batch size and number of workers\n","batch_size = 64\n","num_workers = 4\n","\n","# Create data loaders for the train, validation, and test datasets\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"],"metadata":{"id":"N8oj5KBqj0KV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(3072, 128)  # First fully connected layer, input size is 3072, output size is 128\n","        self.fc2 = nn.Linear(128, 64)    # Second fully connected layer with 64 units\n","        self.fc3 = nn.Linear(64, 10)     # Output layer with 10 units (classes)\n","\n","    def forward(self, x):\n","        # Flattening the input image\n","        x = x.view(-1, 3072)\n","        # FC1 -> ReLU -> FC2 -> ReLU -> FC3\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","model_MLP = MLP()"],"metadata":{"id":"taned-I9kEzu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.optim as optim\n","# Set batch size and number of workers\n","batch_size = 64\n","num_workers = 4\n","\n","# Create data loaders for the train, validation, and test datasets\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n","# Specify the learning rate for the optimizer\n","learning_rate = 0.01\n","\n","# Create the SGD optimizer with weight_decay\n","optimizer = optim.SGD(model_MLP.parameters(), lr=learning_rate, weight_decay=1e-4)\n","\n","# Define the loss function and optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model_MLP.parameters(), lr=learning_rate, weight_decay=1e-4)\n","\n","# Check if GPU is available and set the device accordingly\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move the model to the chosen device\n","model_MLP.to(device)\n","\n","# Number of epochs\n","num_epochs = 10\n","loss_MLP=0.0\n","# Training loop\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(train_loader, 0):\n","        # Get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data[0].to(device), data[1].to(device)\n","\n","        # Zero the parameter gradients\n","        optimizer.zero_grad()\n","        # Forward pass\n","        outputs = model_MLP(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Print statistics\n","        running_loss += loss.item()\n","        if i % 200 == 199:    # Print every 200 mini-batches\n","            print('[Epoch: %d, Mini-batch: %5d] loss: %.3f' %\n","                  (epoch + 1, i + 1, running_loss / 200))\n","            running_loss = 0.0\n","    loss_MLP=loss\n","print('Finished Training')\n","print(loss_MLP.item())"],"metadata":{"id":"N9Ie-HFskNJl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we start to train the CNN model."],"metadata":{"id":"2crLdNKylN2K"}},{"cell_type":"code","source":["import torch.nn as nn\n","\n","class ArchitecturalBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, down_sample=False):\n","        super(ArchitecturalBlock, self).__init__()\n","\n","        # Define the first convolutional layer\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        # Define the second convolutional layer\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # Store parameters for downsampling and stride\n","        self.down_sample = down_sample\n","        self.stride = stride\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","\n","    def down_sampling(self, x):\n","        # Implement down-sampling\n","        out = F.pad(x, (0, 0, 0, 0, 0, self.out_channels - self.in_channels))\n","        out = nn.MaxPool2d(2, stride=self.stride)(out)\n","        return out\n","\n","    # Define the forward pass for the block\n","    def forward(self, x):\n","        # Save a copy of the input for the residual connection\n","        shortcut = x\n","\n","        # Apply the first convolutional layer, batch normalization, and ReLU activation\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = nn.ReLU()(out)\n","\n","        # Apply the second convolutional layer and batch normalization\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        # Apply down-sampling to the shortcut if needed\n","        if self.down_sample or self.in_channels != self.out_channels:\n","            shortcut = self.down_sampling(shortcut)\n","\n","        # Add the shortcut connection to the output and apply ReLU thereafter\n","        out += shortcut\n","        out = nn.ReLU()(out)\n","\n","        return out\n","\n"],"metadata":{"id":"Rz1e0X4hlUR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self, num_layers, block, num_classes=10):\n","        super(Model, self).__init__()\n","        self.num_layers = num_layers\n","\n","        # input(channel:3) -> (conv 3x3) -> (bn) -> (relu) -> output(channel:16)\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","        # Define layers\n","        self.layers_2n = self.get_layers(block, 16, 16, stride=1)  # feature map size = 16x32x32\n","        self.layers_4n = self.get_layers(block, 16, 32, stride=2)  # feature map size = 32x16x16\n","        self.layers_6n = self.get_layers(block, 32, 64, stride=2)  # feature map size = 64x8x8\n","\n","        # Output layers\n","        self.avg_pool = nn.AvgPool2d(8, stride=1)\n","        self.fc_out = nn.Linear(64, num_classes)\n","\n","        # Initialize weights\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def get_layers(self, block, in_channels, out_channels, stride):\n","        if stride == 2:\n","            down_sample = True\n","        else:\n","            down_sample = (in_channels != out_channels)\n","\n","        layer_list = nn.ModuleList([])\n","        # Downsample on first block if stride is 2\n","        layer_list.append(block(in_channels, out_channels, stride, down_sample))\n","\n","        # Remaining blocks\n","        for _ in range(1, self.num_layers):\n","            layer_list.append(block(out_channels, out_channels))\n","\n","        return nn.Sequential(*layer_list)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","\n","        x = self.layers_2n(x)\n","        x = self.layers_4n(x)\n","        x = self.layers_6n(x)\n","\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc_out(x)\n","\n","        return x\n","def model():\n","    block = ArchitecturalBlock\n","    model = Model(3, block)\n","    return model"],"metadata":{"id":"1lJnrA0qlcm5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim.lr_scheduler import StepLR\n","from torch.optim.lr_scheduler import MultiStepLR\n","# Initialize model, loss function, optimizer, and learning rate scheduler\n","model = model()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Move the model to the chosen device\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","\n","# Calculate the milestone epochs\n","batch_size = 64\n","steps_per_epoch = len(train_loader.dataset) / batch_size\n","milestones = [int(32000 / steps_per_epoch), int(48000 / steps_per_epoch)]\n","\n","# Initialize the MultiStepLR scheduler\n","scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n","\n","# Training loop\n","loss_shortcut=0.0\n","num_epochs =  1\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    for i, (inputs, labels) in enumerate(train_loader):\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # Step the scheduler once every batch\n","        scheduler.step()\n","\n","        if (i + 1) % 100 == 0:  # Print every 100 mini-batches\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n","            running_loss = 0.0\n","    loss_shortcut=loss\n","torch.save(model.state_dict(), 'model.pth')"],"metadata":{"id":"D1KcX0hYlhDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plot the loss of CNN model in trainning."],"metadata":{"id":"vv59XI88l08X"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","def model():\n","    block = ArchitecturalBlock\n","    model = Model(3, block)\n","    return model\n","class EarlyStopping:\n","    def __init__(self, patience=5, verbose=False, delta=0, path='model_best.pth'):\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","\n","    def __call__(self, val_loss, model):\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            if self.verbose:\n","                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        if self.verbose:\n","            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n","\n","# Initialize model, loss function, optimizer, and scheduler\n","model_earlystop = model()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model_earlystop.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model_earlystop.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","\n","# Calculate the milestone epochs\n","batch_size = 64\n","steps_per_epoch = len(train_loader.dataset) / batch_size\n","milestones = [int(32000 / steps_per_epoch), int(48000 / steps_per_epoch)]\n","\n","# Initialize the MultiStepLR scheduler\n","scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n","\n","# Training loop with early stopping\n","num_epochs = 10 # Set the number of epochs\n","early_stopping = EarlyStopping(patience=5, verbose=True, path='model_best.pth')\n","loss_earlystop=0.0\n","all_train_losses = []\n","valid_losses = []\n","\n","for epoch in range(num_epochs):\n","    model_earlystop.train()\n","    batch_losses = []\n","\n","    # Training phase\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model_earlystop(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        batch_losses.append(loss.item())\n","        scheduler.step()\n","        loss_earlystop=loss\n","    all_train_losses.extend(batch_losses)\n","\n","    # Validation phase\n","    model_earlystop.eval()\n","    running_val_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model_earlystop(inputs)\n","            val_loss = criterion(outputs, labels)\n","            running_val_loss += val_loss.item()\n","\n","    epoch_val_loss = running_val_loss / len(val_loader)\n","    valid_losses.append(epoch_val_loss)\n","\n","    # Early stopping call\n","    early_stopping(epoch_val_loss, model_earlystop)\n","    if early_stopping.early_stop:\n","        print(\"Early stopping triggered\")\n","        loss_earlystop=epoch_val_loss\n","        break\n","\n","# Plotting training and validation loss per epoch\n","plt.figure(figsize=(10, 5))\n","plt.plot(all_train_losses, label='Training Loss')\n","plt.plot(valid_losses, label='Validation Loss')\n","plt.title(\"Training and Validation Loss per Epoch\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()\n","\n","# Load the best model for evaluation on test set\n","model_earlystop.load_state_dict(torch.load('model_best.pth'))\n","\n","# Test phase\n","model_earlystop.eval()\n","running_test_loss = 0.0\n","with torch.no_grad():\n","    for inputs, labels in test_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        outputs = model_earlystop(inputs)\n","        test_loss = criterion(outputs, labels)\n","        running_test_loss += test_loss.item()\n","\n","average_test_loss = running_test_loss / len(test_loader)\n","print(f'Average Test Loss: {average_test_loss:.4f}')"],"metadata":{"id":"c-4B4YkDltgT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Finally we create a copy of Architecture Block without shortcut, then we do the comparsion of these three models."],"metadata":{"id":"qhj9yUa1mTnE"}},{"cell_type":"code","source":["class ArchitecturalBlockNoShortcut(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1, down_sample=False):\n","        super(ArchitecturalBlockNoShortcut, self).__init__()\n","\n","        # Define the first convolutional layer\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","\n","        # Define the second convolutional layer\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        # Store parameters for downsampling and stride\n","        self.down_sample = down_sample\n","        self.stride = stride\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","\n","    def down_sampling(self, x):\n","        # Implement down-sampling here using the appropriate method or layer\n","        out = F.pad(x, (0, 0, 0, 0, 0, self.out_channels - self.in_channels))\n","        out = nn.MaxPool2d(2, stride=self.stride)(out)\n","        return out\n","\n","    # Define the forward pass for the block\n","    def forward(self, x):\n","        # Save a copy of the input for the residual connection\n","        shortcut = x\n","\n","        # Apply the first convolutional layer, batch normalization, and ReLU activation\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = nn.ReLU()(out)\n","\n","        # Apply the second convolutional layer and batch normalization\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        return out\n","\n","\n","\n","\n","def model2():\n","    block = ArchitecturalBlockNoShortcut\n","    model2 = Model(3, block)\n","    return model2\n","\n","#Train it in the same way with early stop\n","# Initialize model, loss function, optimizer, and scheduler\n","model_noshortcut = model2()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model_noshortcut.to(device)\n","model\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(model_noshortcut.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n","\n","# Calculate the milestone epochs\n","batch_size = 64\n","steps_per_epoch = len(train_loader.dataset) / batch_size\n","milestones = [int(32000 / steps_per_epoch), int(48000 / steps_per_epoch)]\n","\n","# Initialize the MultiStepLR scheduler\n","scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n","\n","# Training loop with early stopping\n","num_epochs = 10  # Set the number of epochs\n","early_stopping = EarlyStopping(patience=5, verbose=True, path='model_best.pth')\n","lose_earlystop=0.0\n","all_train_losses = []\n","valid_losses = []\n","\n","for epoch in range(num_epochs):\n","    model_noshortcut.train()\n","    batch_losses = []\n","\n","    # Training phase\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model_noshortcut(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        batch_losses.append(loss.item())\n","        scheduler.step()\n","        loss_noshortcut=loss\n","    all_train_losses.extend(batch_losses)\n","\n","    # Validation phase\n","    model_noshortcut.eval()\n","    running_val_loss = 0.0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model_noshortcut(inputs)\n","            val_loss = criterion(outputs, labels)\n","            running_val_loss += val_loss.item()\n","\n","    epoch_val_loss = running_val_loss / len(val_loader)\n","    valid_losses.append(epoch_val_loss)\n","\n","    # Early stopping call\n","    early_stopping(epoch_val_loss, model_noshortcut)\n","    if early_stopping.early_stop:\n","        print(\"Early stopping triggered\")\n","        loss_noshortcut=epoch_val_loss\n","        break\n","\n","\n"],"metadata":{"id":"-0-66oWAmhVA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot\n","models = ['With Shortcut', 'Without Shortcut', 'MLP']\n","losses = [loss_earlystop.item(), loss_noshortcut.item(), loss_MLP.item()]\n","plt.bar(models, losses)\n","plt.xlabel('Model Type')\n","plt.ylabel('Final Training Loss')\n","plt.title('Comparison of Training Loss Across Different Models')\n","plt.show()"],"metadata":{"id":"VDxGkvQ0mlyw"},"execution_count":null,"outputs":[]}]}